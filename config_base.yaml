# Base configuration with common trainer, data, and callback settings
# This file should be inherited by model-specific configs

# Data configuration - Common for all models
data:
  val_split: 0.2
  batch_size: 16
  num_workers: 0

# Trainer configuration - Common for all models
trainer:
  max_epochs: 100
  accelerator: auto
  devices: auto
  precision: 32
  
  # Common callbacks for all models
  callbacks:
    # Model summary with detailed submodule parameter breakdown
    - class_path: lightning.pytorch.callbacks.ModelSummary
      init_args:
        max_depth: -1  # Show ALL submodules
        
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        monitor: "val_displacement_distance"
        mode: "min"
        save_top_k: 1
        filename: "best-{epoch}-{val_displacement_distance:.4f}"
        
    # Optional: Early stopping (commented out by default)
    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        monitor: "val_displacement_distance"
        mode: "min"
        patience: 20
        min_delta: 1e-6
        
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: "epoch"
    - class_path: src.callbacks.parameter_logger.ParameterCountLogger
      init_args: {} 