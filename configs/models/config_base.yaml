# Base configuration with common trainer, data, and callback settings
# This file should be inherited by model-specific configs

# Data configuration - Common for all models
data:
  val_split: 0.2
  batch_size: 16
  num_workers: 0
  data_dir: "data/processed_dv"

# Trainer configuration - Common for all models
trainer:
  max_epochs: 1000
  max_time: "00:02:00:00"  # Maximum training time of 30 minutes
  accelerator: auto
  devices: auto
  precision: 32
  # gradient_clip_val: 0.5  # FIXED: More conservative gradient clipping
  # gradient_clip_algorithm: "norm"
  # Common callbacks for all models
  callbacks:
    # Model summary with detailed submodule parameter breakdown
    - class_path: lightning.pytorch.callbacks.ModelSummary
      init_args:
        max_depth: -1  # Show ALL submodules
    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        monitor: "val_displacement_distance_epoch"
        mode: "min"
        patience: 10
        verbose: true
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        monitor: "val_displacement_distance_epoch"
        mode: "min"
        save_top_k: 1
        verbose: false
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: "epoch"
    - class_path: src.callbacks.parameter_logger.ParameterCountLogger
      init_args: {} 